{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#1. 資料前處理\n",
    "#a. 讀取csv檔僅保留\"text\"、\"stars\"兩個欄位，並將stars欄位內值大於等於4的轉成1，其餘轉成0，1: positive; 0: negative\n",
    "df = pd.read_csv(\"./Data/yelp.csv\")\n",
    "df = df[[\"stars\", \"text\"]]\n",
    "df['stars'] = df['stars'].map(lambda x: 1 if x >= 4 else 0)  # 二元分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeweilin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#b.去除停頓詞stop words \n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# 去除停用詞\n",
    "nltk.download('stopwords')\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "stop_words = nltk_stopwords\n",
    "\n",
    "# 文字轉向量：CountVectorizer 和去除停用詞\n",
    "corpus = df[\"text\"].tolist()\n",
    "vectorizer = CountVectorizer(stop_words=stop_words, min_df=0.01)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    00   10  100        11   12   15   20   25   30   40  ...  yeah  year  \\\n",
      "0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "1  0.0  0.0  0.0  0.106818  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "2  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "3  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "4  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
      "\n",
      "   years  yelp  yes  yet  young  yum  yummy  y  \n",
      "0    0.0   0.0  0.0  0.0    0.0  0.0    0.0  1  \n",
      "1    0.0   0.0  0.0  0.0    0.0  0.0    0.0  1  \n",
      "2    0.0   0.0  0.0  0.0    0.0  0.0    0.0  1  \n",
      "3    0.0   0.0  0.0  0.0    0.0  0.0    0.0  1  \n",
      "4    0.0   0.0  0.0  0.0    0.0  0.0    0.0  1  \n",
      "\n",
      "[5 rows x 1049 columns]\n"
     ]
    }
   ],
   "source": [
    "# 使用 TF-IDF 轉換文本\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(X)\n",
    "tfidf_vec = tfidf.toarray()\n",
    "\n",
    "# 創建 DataFrame 包含 TF-IDF 向量及其標籤\n",
    "tfidf_df = pd.DataFrame(tfidf_vec, columns=features)\n",
    "tfidf_df['y'] = df['stars']\n",
    "\n",
    "# 去除缺失值\n",
    "tfidf_df = tfidf_df.dropna()\n",
    "\n",
    "# 顯示 DataFrame\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_seg_binary_list = X.toarray()\n",
    "text_seg_list = []\n",
    "\n",
    "for row in text_seg_binary_list:\n",
    "    temp_list = [features[j] for j in range(len(row)) if row[j] == 1]\n",
    "    text_seg_list.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0 -0.055891  0.119856 -0.055028 -0.003073 -0.047791 -0.006065  0.058628   \n",
      "1  0.022537 -0.009645  0.039787 -0.065693 -0.117083  0.080017  0.114434   \n",
      "2  0.133588 -0.117555  0.243738 -0.074329 -0.337692  0.185905  0.294554   \n",
      "3 -0.109145  0.077581  0.071527 -0.066897 -0.020368 -0.261418  0.243756   \n",
      "4 -0.115342  0.146493 -0.168324 -0.078551 -0.047777 -0.153304  0.091618   \n",
      "\n",
      "          7         8         9  ...       241       242       243       244  \\\n",
      "0  0.043664 -0.017931 -0.087957  ...  0.089980 -0.017116  0.094483  0.046779   \n",
      "1  0.004489 -0.065123 -0.057993  ...  0.096067  0.034653  0.166542 -0.026478   \n",
      "2 -0.172235 -0.144143 -0.564826  ...  0.480761 -0.034307  0.284486  0.115924   \n",
      "3 -0.227156  0.234997 -0.065524  ...  0.152017 -0.064036  0.148587 -0.097497   \n",
      "4 -0.142137  0.130455  0.099909  ...  0.130070  0.071522  0.116430 -0.077419   \n",
      "\n",
      "        245       246       247       248       249  y  \n",
      "0  0.048924  0.002736  0.086016  0.015578  0.029341  1  \n",
      "1 -0.047246  0.157409 -0.040893 -0.046655  0.070571  1  \n",
      "2 -0.099643  0.033119 -0.021617 -0.179156 -0.017467  1  \n",
      "3 -0.230133 -0.223155  0.219576 -0.018940 -0.001808  1  \n",
      "4 -0.200106 -0.057803  0.141568  0.091417  0.092117  1  \n",
      "\n",
      "[5 rows x 251 columns]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 訓練 Word2Vec\n",
    "vector_size = 250\n",
    "model = Word2Vec(sentences=text_seg_list, vector_size=vector_size, epochs=10)\n",
    "\n",
    "# word embedding\n",
    "word2vec_vec = [] \n",
    "for i in range(len(text_seg_list)):\n",
    "    vector_sum = np.zeros(vector_size)\n",
    "    count = 0\n",
    "    for j in range(len(text_seg_list[i])):\n",
    "        word = text_seg_list[i][j]\n",
    "        if word in model.wv:  # 檢查詞是否在模型的詞彙中\n",
    "            vector_sum += model.wv[word]\n",
    "            count += 1\n",
    "    \n",
    "    if count > 0:  # 確保不會除以零\n",
    "        vector_average = vector_sum / count\n",
    "    else:\n",
    "        vector_average = np.zeros(vector_size)  # 若沒有有效詞向量，則使用零向量\n",
    "    \n",
    "    word2vec_vec.append(vector_average.tolist())\n",
    "\n",
    "# 將結果放入 DataFrame\n",
    "word2vec_df = pd.DataFrame(word2vec_vec)\n",
    "word2vec_df['y'] = df['stars']\n",
    "word2vec_df = word2vec_df.dropna()\n",
    "\n",
    "# 顯示結果\n",
    "print(word2vec_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def K_fold_CV(k, data, model):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=123)  # 使用 KFold 進行資料分割\n",
    "    Accuracy = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(data), 1):\n",
    "        print(f\"目前 test fold = {fold}\", end=\" \")\n",
    "        \n",
    "        train_x, test_x = data.iloc[train_idx].drop(\"y\", axis=1), data.iloc[test_idx].drop(\"y\", axis=1)\n",
    "        train_y, test_y = data.iloc[train_idx][\"y\"], data.iloc[test_idx][\"y\"]\n",
    "        \n",
    "        model.fit(train_x, train_y)\n",
    "        test_y_predicted = model.predict(test_x)\n",
    "\n",
    "        acc = accuracy_score(test_y, test_y_predicted)  # 計算準確度\n",
    "        Accuracy.append(acc)\n",
    "        \n",
    "        print(f\", accuracy = {round(acc, 4)}\")\n",
    "\n",
    "    avg_acc = np.mean(Accuracy)\n",
    "    print(\"---------------------------------------\")\n",
    "    print(f\"Average accuracy: {round(avg_acc, 4)}\")\n",
    "    #return round(avg_acc, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前 test fold = 1 , accuracy = 0.8012\n",
      "目前 test fold = 2 , accuracy = 0.8088\n",
      "目前 test fold = 3 , accuracy = 0.802\n",
      "目前 test fold = 4 , accuracy = 0.8\n",
      "---------------------------------------\n",
      "Average accuracy: 0.803\n"
     ]
    }
   ],
   "source": [
    "# 建立隨機森林模型\n",
    "forest = RandomForestClassifier(n_estimators=200, criterion=\"entropy\", random_state=123)\n",
    "# 執行 4-fold CV\n",
    "K_fold_CV(4, tfidf_df, forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前 test fold = 1 , accuracy = 0.7004\n",
      "目前 test fold = 2 , accuracy = 0.6964\n",
      "目前 test fold = 3 , accuracy = 0.7008\n",
      "目前 test fold = 4 , accuracy = 0.7032\n",
      "---------------------------------------\n",
      "Average accuracy: 0.7002\n"
     ]
    }
   ],
   "source": [
    "# 建立 random forest 模型\n",
    "forest = RandomForestClassifier(n_estimators = 200, criterion=\"entropy\", random_state=123)\n",
    "# word2vec 4-fold cv\n",
    "K_fold_CV(4, word2vec_df, forest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
